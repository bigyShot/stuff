Mysql

sql执行流程:

Tomcat-->数据库连接池-->mysql的数据库连接池-->线程接收此条网络请求-->sql接口-->sql解析器解析sql

--->查询优化器(最优查询路劲)-->执行器(执行计划)-->存储引擎---缓冲池/磁盘/缓冲池&磁盘

这里除了存储引擎其余的基本都是固定通用的,只有存储引擎是可以变化的,比如Myisam,InnoDB,Memory

![image-20210319144513133](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210319144513133.png)



Mysql在更新数据的时候,首先如果数据不在缓冲池中,那就查到它,将其加载到缓冲池中来,然后现在缓冲池中对其进行修改,修改的同时会写一个redo.log,这个文件是用来保存修改记录的,他首先也是写在一个缓冲中,等事务执行完之后(单条sql也是一个事务),然后再将redo.log以及数据刷到磁盘中.

redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。
undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。

将redo日志从redo log buffer中刷到磁盘文件是有一个策略的,通过innodb_flush_log_at_trx_commit来配置,
当参数为0时,可能即使事务已提交完成,也还没有把redo.log刷入磁盘,此时如果宕机,那redo数据就丢了
![image-20210319150139061](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210319150139061.png)

当参数为1的时候,那再提交事务的时候必须吧redo.log刷到磁盘里去,那么就是只要事务提交成功,那么redo.log一定在磁盘里了
当参数为2的时候,会将redo.log写到os cache里去,可能1s后会刷入磁盘,同样面临宕机会丢数据.

![image-20210319155526938](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210319155526938.png)



**BufferPool**

mysql中的数据是以数据页的形式存在的(一页中包含多行数据),一页数据页大小为16K,bufferPool从磁盘加载数据时就是加载数据所在的数据页到BufferPool,BufferPool中有个对应的叫缓存页,也是16K,但是BufferPool中还有对于缓存页的描述数据,描述这个页在磁盘中的位置等.大小相当于缓存页的5%左右

BufferPool的默认值大小是128M,实际环境中可以根据服务器大小进行调整,可以调大一点.如果设的是128M的话,那实际大小应该在130多M,缓存页的描述数据是不计算在分配给BufferPool的大小里面的.

![image-20210428094548129](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210428094548129.png)



从磁盘加载数据到BufferPool时,我们需要找到空闲的缓存页,这时候通过free链表来查找,它是一个双向链表数据结构,每个节点就是一个描述空闲的缓存页的地址的描述数据

free链表就是由描述数据作为节点组成的

加载数据页到缓存的过程就是查找free链表,拿到一个空闲页的地址,然后从free链表中剔除掉这块描述数据

**数据库中还有一个哈希表,以表空间号+数据页号作为key,缓存页的地址作为value**

当需要使用一个数据页的时候,通过表空间号+数据页号作为key去这个哈希表里查,如果没有就读取数据页,有了就直接可以读缓存页了

![image-20210428095919997](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210428095919997.png)

既然会读取磁盘数据到缓存中,那么必然会存在脏数据的问题,也就是缓存中的数据经过操作之后与磁盘数据不一致了,那么就需要将缓存数据刷到磁盘中去,但是并不是所有的缓存页都是脏数据,因此也不能一次将所有缓存数据刷到磁盘,所以出现flush链表,通过这个来记录脏数据页.一旦有缓存页的数据被修改过了,就将这个缓存页的地址引用添加到flush链表中.



**基于LRU淘汰缓存**

随着缓存页的时候,缓存必然会被用完,那么此时需要加载新的数据时怎么办?那就将旧的缓存数据刷到磁盘中去,空出缓存页来.刷缓存数据到磁盘基于LRU来计算,通过维护一个LRU链表,需要缓存页时,将链表尾部的缓存页刷到磁盘.

**预读**

在Mysql中,加载数据页到BufferPool时可能会触发预读机制,将相邻的数据页也一并加载到缓存,放入LRU链表的前端.

预读触发机制:

1.参数innodb_read_ahead_threshold,默认值是56,如果顺序的访问了一个区里的多个数据页,访问的数据页的数量超过了这个阈值,此时就会触发预读机制,把一个相邻区的所有数据页都加载到缓存里去

2.如果BufferPool里缓存了一个区里的13个连续的数据页,而且这些数据页都是比较频繁会被访问的,此时就会触发预读机制,把这个区里的其他的数据页都加载到缓存里去

机制2是通过参数innodb_random_read_ahead来控制的,默认是off 关闭的

所以简单的预读机制下,不如触发情况1 ,一下子加载很多相邻区里的数据页到缓存里,这些缓存页会被一下加载到LRU的前面,导致本来访问频繁的缓存页到了LRU的尾端,继而被淘汰刷入磁盘,这就完全不合理了

**冷热分离LRU**

实际的mysql中使用LRU是有冷热分离的,一个链表逻辑上被分为冷热两端,刚进入缓存的是放进冷数据区的头部的,在1s后再次被访问的话,就会进入热数据区的头部.
冷热数据比例是由innodb_old_blocks_pct参数控制的,默认为37,也就是冷数据占比37%,需要淘汰数据时直接淘汰冷数据区尾部即可

![image-20210428140930092](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210428140930092.png)



**LRU热数据区的优化**

按最初设计来说,热数据区的节点每次被访问都将它移到热数据前头去,但是热数据区的缓存是有可能经常被访问的,在并发量很高的情况下,这样频繁的移动本身就会对LRU链表造成很大的压力,因此可以优化为只有后3/4的热数据在被访问时移到前头去,前1//4不必移动.



**冷热分离LRU思想的实际应用**

电商系统中访问到的商品都会加载到redis中去,可以统计下每天被访问的商品的次数,第二天可以把热数据预加载redis中去



Mysql中不是只有BufferPool满了的时候才会刷缓存页到磁盘中去,而是会定时刷盘

定时刷盘首先会将冷数据区的数据页刷磁盘,但也不可能永远不刷热数据,因此这个线程会在Mysql不是很繁忙的时候把Flush链表中的缓存页都刷入磁盘

![image-20210428142525283](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210428142525283.png)

刷盘的过程就是减少flush链表和LRU链表的节点数,增加free的节点数



**在执行CRUD操作的时候,如果没有缓存页,那么需要先从冷数据区将缓存页刷到磁盘,然后再从磁盘取数据刷到缓存页,如果频繁的出现这样一个状况,那就相当于每次CRUD都要进行两次磁盘IO,该如何优化这种情况?**

#### 优化这种情况说白了就是避免缓存页被频繁的使用完毕,首先在后台有一个线程会定时刷缓存页到磁盘,会释放一部分,但是这个过程很难优化,要是释放的过于频繁,那么后台线程执行磁盘IO过于频繁也会影响数据库的性能.所以关键就在于bufferPool有多大,所以核心优化点就是加大bufferPool的大小和数量

**在实际环境中,一般是多个请求同时打过来mysql,多个线程分别处理多个请求,而CRUD操作都是基于BufferPool和lru,flush,free这些链表来操作的,那么多线程情况下就会有并发问题,因此需要对BufferPool加锁,因为是基于内存的指针操作,会很快.但是再快也是串行操作,特别是有时候还需要进行磁盘IO,耗时就会更多一些**

**通过加大BufferPool来优化,MySQL默认规则是如果BufferPool分配的内存小于1GB,那么就只会给一个BufferPool,但是如果机器内存很大的情况,可以给BufferPool分配较大的内存,比如8GB,此时是可以设置多个BufferPool的,比如说如下配置**

**innodb_buffer_pool_size = 8589934592**
**innodb_buffer_pool_instances = 4**

**设置4个BufferPool,每个2G,此时Mysql就拥有了4个BufferPool了,每个BufferPool负责管理一部分的缓存页和描述数据块,有自己独立的free,flush,lru等链表,那么此时多线程并发访问,就把锁的粒度更细化了,就把压力分散开了,这样可以成倍提升多线程访问性能**

![image-20210428144410391](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210428144410391.png)

Mysql对于buffer pool有一个chunk机制,也就是buffer pool是由很多chunk组成的,他的大小是由innodb_buffer_pool_chunk_size参数控制的,默认值是128M

比如一个2G的buffer pool,那它就有16个chunk,每个chunk里就是一系列的描述数据块和缓存页,每个bufferPool里的多个chunk共享一套free,flush,lru链表

<img src="C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210428144928891.png" alt="image-20210428144928891" style="zoom:80%;" />

**在没有chunk机制时是无法动态调整bufferPool的大小的,比如说加大内存,那么需要申请一块新的内存空间,然后把旧的数据全部移到新内存中去,这样是很耗时的,性能也很低下,在运行时是绝对不可接受的.**

**那么基于chunk机制可以在运行时动态调整bufferPool的大小了,比如现在8G,需要加到16G,那么现在只需要申请一系列的128M大小的chunk就可以了,只要每个chunk是连续的128M内存就行了,然后把这些申请到的chunk分配给bufferPool就行了,就不需要申请16G的连续空间再拷贝数据了**



实际生产环境建议给bufferPool设置为机器内存的50%~60%左右,设置bufferPool的数量和chunk的大小时记住一个公式 
bufferPool总大小=(chunk大小*bufferPool数量)的整数倍,且必须为整数倍

比如现在分配20G给BufferPool,设置16个bufferPool,那大小就是(16*128M)=2G,是10倍,符合要求
比如设置32个bufferPool,是5倍,也符合.但如果设置成31个bufferPool,20G/(31x128M),无法整除就不行了,会导致Mysql自动调整为相应倍数



**行数据的物理存储结构**

倒序排列变长非NULL字段的长度  NULL字段的bit值倒序   头信息(40位)  DB_ROW_ID DB_TRX_ID  DB_ROL_PTR 字段值

exam:   jack NULL m NULL school

物理结构:    0x06  0x04 00000101 0000000000000000000010000000000000011001 000000000094C  0000000000032D EA0000010078Ejava	jack m school



实际数据页存储结构

![image-20210430154054239](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210430154054239.png)

![image-20210430154007646](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210430154007646.png)

 Linux的IO

1.当Mysql发起一次数据页的随机读写,指令首先来到VFS层,然后根据指向的目录来决定交给哪个文件系统,比如有的文件是NFS文件系统管理的,有的是Ext3文件系统管理的,VFS层就是把请求交给对应的文件系统.

2.接着文件系统会先在page cache这个基于内存的缓存里找请求的数据,如果找到了就基于内存缓存来执行读写,没有就继续走下一层

3.此时来到通用Block层,这一层会把对文件的IO请求转换为Block IO请求

4.转换为Block IO以后再交给IO调度层,这一层默认是用CFQ公平调度算法(也就是如果有2个SQL语句同时进来,会更新到多个Block,如果此时是基于此,会先执行读取数据量更大的IO操作的SQL,耗时很久,然后再执行少的那一个),所以一般生产环境需要调整为deadline IO调度算法,核心思想是任何一个IO操作都不能一直的等待,在指定时间范围内,必须让他去执行,所以基于deadline算法,第一个更新少量数据的IO操作可能在等待一会之后就会得到执行的机会

5.经过IO调度之后,会决定那个IO请求先执行,哪个后执行,此时执行的IO请求就会交给Block设备驱动层,最后通过驱动把IO请求发送给真正的存储硬件,也就是Block设备层

![image-20210506150028829](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210506150028829.png)	

最终硬件设备完成了IO读写操作之后,最后把响应经过上面的层级反向依次返回,最终Mysql可以得到本次IO读写操作的结果



RAID

磁盘冗余阵列,就是对多块磁盘的一个管理技术,在数据写入磁盘时会帮你选择写到哪块磁盘,读取时会选择从哪块读,在多块磁盘组成RAID阵列的时候,一般会有一个RAID卡,RAID卡中有个SDRAM,就是一块缓存,基于内存,然后把RAID的缓存模式设置为write back,数据就会先写到SDRAM,再写到磁盘,这样的一个数据缓冲概念,可以大大提升写入速度

但如果突然断电,SDRAM里的数据还没来得及写入磁盘,就会导致数据丢失,怎么办呢,因此SDRAM引入了锂电池,而锂电池的电也是会用完的,所以要定时对锂电池进行充放电.在锂电池平时正常工作时,RAID的模式设置为Write back,但是在锂电池自动充放电的过程中,RAID的缓存级别就会变成write through,此时通过RAID写数据就会直接写到磁盘了,性能会退化10倍左右.

RAID0 多个磁盘组成阵列,所有数据分散写入不同磁盘,整体容量很大,并发能力很强,但是坏了其中一块,数据就丢失了

RAID1 多个磁盘组成阵列,两块磁盘互为镜像关系,写的所有数据在两块磁盘上都有,形成数据冗余,一块坏了也不打紧

线上可以采用RAID10,就是RAID0和RAID1结合,比如采用6块磁盘,两两互为镜像,组成一个RAID1,然后6块就可以组成3组RAID1,再以RAID0的思路来看,不同组的数据又是不一样的.



**有时突然数据库性能几十倍抖动的原因**

所以一旦面临锂电池充放电的时候,可能会导致数据库服务器的RAID存储性能出现几十倍的抖动,会间接因为锂电池周期性的充放电而导致数据库每隔一段时间就会出现性能几十倍的抖动

解决方案:

1.锂电池换成电容,电容不用频繁充放电,导致性能抖动,且可以自动检查电量,自动充电,但更换电容很麻烦,且电容比较容易老化

2.手动充放电,比如写个脚本,定时在凌晨2,3点那种流量很低的时候进行充放电



**Mysql的最大连接数跟linux的最大文件句柄数有关系,有时候如果发现mysql最大连接数很小,客户端报了too many connections的时候,可以检查一下linux的文件句柄数**





**Redo log**

Mysql写redo log时是写入redo log block这样一个数据结构,每个block大小为512字节,其中header占12字节,trailer占4字节,body占496字节.

![image-20210508140732014](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508140732014.png)

**redo log buffer**

在mysql中,有一个redo log buffer,作用其实和buffer pool类似,也就是一个缓冲区,通过设置innodb_log_buffer_size可以指定这个redo log buffer的大小,默认是16M.写redo log时先写入内存里的redo log block,然后再通过这个刷到磁盘.

平时执行一个事务的过程中,会有CRUD操作,那就有多个redo log,那么这多个redo log就是一组redo log,每次一组redo log都是先在别的地方暂存,然后都执行完了,再把一组redo log写入到redo log buffer的block去的.

如果一组redo log实在太多了,那么就可能会存在一组log存放在两个block里的情况,一组太小,也可能会存在多组log存在一个block的情况

![image-20210508141422418](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508141422418.png)

![image-20210508141348346](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508141348346.png)

**redo log buffer刷进磁盘的时机**

1.如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了,也就是超过了8MB的redo log在缓冲里了,此时就回刷入磁盘

2.一个事务提交的时候,必须把他的redo log所在的redo log block都刷到磁盘文件去,只有这样,当事务提交之后,他修改的数据绝对不会丢失,因为redo log有重做日志,随时可以恢复事务做的修改(当然,刷入磁盘其实也是先进入到系统的os cache里,想要保证事务的数据绝对不丢,还得强行从os cache刷入物理磁盘,有个参数可以设置)

3.后台线程定时刷新,有一个后台线程每隔1s就会把redo log buffer里的redo log block刷到磁盘文件里去

4.Mysql关闭的时候,redo log block都会刷入到磁盘里去

**redo log日志文件**

随着log不断增长,磁盘空间占用肯定会越来越大.redo log文件是有多个的,写满了一个就会写下一个redo log,通过Innodb_log_file_size可以指定每个redo log文件的大小,默认是48M,通过Innodb_log_files_in_group可以指定文件的数量,默认是2个.

所以默认情况下,指定的目录里就只有2个日志文件,每个48M,先写第一个,满了再写第二个,如果都满了就继续写第一个,覆盖第一个文件里之前的redo log.



**undo log 回滚日志**

![image-20210508143918333](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508143918333.png)

INSERT语句的undo log的类型是TRX_UNDO_INSERT_REC，这个undo log里包含了以下一些东西：

这条日志的开始位置

主键的各列长度和值

表id

undo log日志编号

undo log日志类型

这条日志的结束位置

那么主键的各列长度和值是什么意思？大家都知道，你插入一条数据，必然会有一个主键！
如果你自己指定了一个主键，那么可能这个主键就是一个列，比如id之类的，也可能是多个列组成的一个主键，比如“id+name+type”三个字段组成的一个联合主键，也是有可能的。

所以这个主键的各列长度和值，意思就是你插入的这条数据的主键的每个列，他的长度是多少，具体的值是多少。即使你没有设置主键，MySQL自己也会给你弄一个row_id作为隐藏字段，做你的主键。
接着是表id，这个就不用多说了，你插入一条数据必然是往一个表里插入数据的，那当然得有一个表id，记录下来是在哪个表里插入的数据了。undo log日志编号，这个意思就是，每个undo log日志都是有自己的编号的。而在一个事务里会有多个SQL语句，就会有多个undo log日志，在每个事务里的undo log日志的编号都是从0开始的，然后依次递增。

至于undo log日志类型，就是TRX_UNDO_INSERT_REC，insert语句的undo log日志类型就是这个东西。

最后一个undo log日志的结束位置，这个自然也不用多说了，他就是告诉你undo log日志结束的位置是什么。

那么接着我们用一个图画一下这个INSERT语句的undo log回滚日志的结构，大家来看一眼，感受一下。

![image-20210508144401830](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508144401830.png)







脏读:事务A来更改数据的值a为x,此时事务B进来,读取数据值为x,然后在此基础上做一些业务,此时A事务突然发生了回滚,值x又变成了a,此时事务B发现不对劲啊,和之前的值不一样了,这就是脏读.  执行事务的过程中值不一样

脏写:事务AB来了.A先操作把a改成了x,然后B又把x改成了y,此时B提交了,但之后A却因为事故回滚了,此时B基于x改成了y之后,y又回滚成了a,此时就相当于B执行完了,但是没起作用

不可重复读:事务A进来读取a的值为x,此时B来把a改成了y,A又去读,发现变成了y,和第一次读的不一样了,此时C又来改,把a又改成了z,A此时再来读,又不一样,但是业务一般是要求在单次业务处理过程中读到的值是一样的,那么这种情况就是不可重复读

幻读: 一个事务用一个SQL多次查询,每次查询都发现查到了之前没看到过的数据



SQL标准四大事务隔离级别:

read uncommitted读未提交:  不允许发生脏写,即不可能两个事务在没提交的情况下去更新同一行数据的值

read committed读已提交:   不允许发生脏写和脏读,即不可能读到别的事务未提交情况下修改的值

repeatable read可重复读:  不会发生脏写,脏读,可重复读,事务一旦开始,多次查询一个值会一直都是一样的,不会读到别人提交事务修改过的值,但避免不了幻读

serializable串行化:  不允许多事务并发执行



Mysql默认是RR级别(可以避免幻读),基于MVCC,多版本控制隔离机制

除非业务需要,在事务执行期间多次查询的时候,必须要查到别的已提交事务修改过的最新的值,不然不要去改隔离级别!如果硬是要,可以修改,比如spring的事务,可以通过注解的isolation的值修改



**undo  log 版本链**

mysql中每条数据都有两个隐藏字段,一个是trx_id,是最近一次更新这条数据的事务id,另一个是roll_pointer,指向更新这个事务之前生产的undo log

现在假设有一个事务A（id=50），插入了一条数据，那么此时这条数据的隐藏字段以及指向的undo log如下图所示，插入的这条数据的值是值A，因为事务A的id是50，所以这条数据的txr_id就是50，roll_pointer指向一个空的undo log，因为之前这条数据是没有的。

![image-20210508160257042](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508160257042.png)

多次修改之后

![image-20210508160422998](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508160422998.png)

多个事务串行执行的事,每个人修改了一行数据,都会更新隐藏字段trx_id和roll_pointer,同时之前多个数据快照对应的undo log,会通过roll_pointer指针串联起来,形成undo log版本链



**ReadView机制**  基于undo log多版本链条

假设原来数据库里就有一行数据，很早以前就有事务插入过了，事务id是32，他的值就是初始值，如下图所示。

![image-20210508163917569](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508163917569.png)

接着呢，此时两个事务并发过来执行了，一个是事务A（id=45），一个是事务B（id=59），事务B是要去更新这行数据的，事务A是要去读取这行数据的值的

![image-20210508164002092](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508164002092.png)

现在事务A直接开启一个ReadView，这个ReadView里的m_ids就包含了事务A和事务B的两个id，45和59，然后min_trx_id就是45，max_trx_id就是60，creator_trx_id就是45，是事务A自己。

这个时候事务A第一次查询这行数据，会走一个判断，就是判断一下当前这行数据的txr_id是否小于ReadView中的min_trx_id，此时发现txr_id=32，是小于ReadView里的min_trx_id就是45的，说明你事务开启之前，修改这行数据的事务早就提交了，所以此时可以查到这行数据，如下图所示

![image-20210508164039581](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508164039581.png)

接着事务B开始动手了，他把这行数据的值修改为了值B，然后这行数据的txr_id设置为自己的id，也就是59，同时roll_pointer指向了修改之前生成的一个undo log，接着这个事务B就提交了，如下图所示。

![image-20210508164105608](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508164105608.png)

这个时候事务A再次查询，此时查询的时候，会发现一个问题，那就是此时数据行里的txr_id=59，那么这个txr_id是大于ReadView里的min_txr_id(45)，同时小于ReadView里的max_trx_id（60）的，说明更新这条数据的事务，很可能就跟自己差不多同时开启的，于是会看一下这个txr_id=59，是否在

ReadView的m_ids列表里？果然，在ReadView的m_ids列表里，有45和59两个事务id，直接证实了，这个修改数据的事务是跟自己同一时段并发执行然后提交的，所以对这行数据是不能查询的！如下图所示。

那么既然这行数据不能查询，那查什么呢？

简单，顺着这条数据的roll_pointer顺着undo log日志链条往下找，就会找到最近的一条undo log，trx_id是32，此时发现trx_id=32，是小于ReadView里的min_trx_id（45）的，说明这个undo log版本必然是在事务A开启之前就执行且提交的。

好了，那么就查询最近的那个undo log里的值好了，这就是undo log多版本链条的作用，他可以保存一个快照链条，让你可以读到之前的快照值，如下图。

 

![image-20210508164212511](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508164212511.png)

接着假设事务A自己更新了这行数据的值，改成值A，trx_id修改为45，同时保存之前事务B修改的值的快照，如下图所示。

![image-20210508164444568](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508164444568.png)

接着在事务A执行的过程中，突然开启了一个事务C，这个事务的id是78，然后他更新了那行数据的值为值C，还提交了，如下图所示

![image-20210508164605256](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508164605256.png)

​	这个时候事务A再去查询，会发现当前数据的trx_id=78，大于了自己的ReadView中的max_trx_id（60），此时说明什么？

说明是这个事务A开启之后，然后有一个事务更新了数据，自己当然是不能看到的了！

 此时就会顺着undo log多版本链条往下找，自然先找到值A自己之前修改的过的那个版本，因为那个trx_id=45跟自己的ReadView里的creator_trx_id是一样的，所以此时直接读取自己之前修改的那个版本，如下图。

![image-20210508164648183](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210508164648183.png)



**RR对于幻读问题的解决程度,两个事务AB同时进来,A先查询,B新增了数据,并已提交,如果A后面只是又查询,那么是不会出现幻读的,只能读到他这个trx_id之前的值.但是如果A后面进行了新增或更改,那trx_id就会变大,大于已提交的B的trx_id,那么再次查询的话就会查到B提交的值,就会造成幻读.**
**因此RR不能彻底解决幻读**,rr级别下的锁策略默认是next-key lock(锁定一个范围内的索引,包括自身),此外行锁还有record lock(锁定指定行),gap locks(锁定一个范围内的索引,除了指定行)



**mysql innodb，在RR级别下，是否会产生幻读？**

严格来说，是会产生幻读的，在RR隔离级别下，如果只是普通的select * from user where id > 1, 查询走的都是undo log 链，这种就叫做快照读
那么此时事务B插入了一条数据且提交了，这个时候如果事务A, update的时候查询条件也能找到事务B的数据的话，那么连带事务B新插入数据的值也会修改，因为update是当前读，当前读就能读到已经提交了的事务的数据。那么事务A其实会把当前读到的数据修改了后，接着更新到undo log链上，那么再次读这个undo log 链上的快照，其实快照里的内容已经被上次当前读的值覆盖了。所以会读到新的结果出来，那么就发现第一次select和第二次了select出来的结果不一样了，可以说就出现了幻读。

那为了防止这样的现象出现，可以把普通的select * from user where id > 1，加上 for update, 那么这个也叫做当前读，他可以把这个索引查询条件范围内都锁住（通过一种叫做 next key locking 算法）
那么其他事务想往这个索引范围内插入，或者修改这个索引范围内的数据就不行了，如果这个时候还是事务B, 那么事务B会一直阻塞在那里，无法提交，直到事务A提交了，释放了锁，事务B才能继续执行并且提交，这个过程中，事务A也不会读到其他事务提交的数据，自然也就不会有什么幻读产生。



**Mysql线上性能抖动**

1.可能是缓存页满了,而此时来一个sql,要查很多数据,那就需要先将一部分缓存页刷到磁盘上去才有足够的空间给新的数据,而刷盘是很费时间的

2.redo log满了,比如是有2个redo log文件,2个都满了,那现在写新的log就要开始覆盖第一个redo log文件了,但不可能直接覆盖,需要先查一下这个redo log文件中对应的缓存页是否都已经刷到磁盘上去了,不然如果直接覆盖,而下一秒mysql宕机了,那就没有办法恢复mysql的数据了.因此如果恰好碰上redo log文件满了,然后又发现文件1在缓存页中有很多的数据没刷磁盘,那此时还需要先将缓存页的数据刷盘才可以继续执行其他增删操作,因为增删操作是一定要写redo log的

对于1的情况一般是两种解决方法,一是加大buff pool的容量,但是这也只能减少强制刷盘的频率,性能抖动还是存在

另一种就是采用固态硬盘,固态的随机IO读写速度是非常快的,然后再设置一个参数,innodb_io_capacity,这个参数是告诉数据库采用多大似的IO速率把缓存页flush到磁盘里去的.加入ssd最多可以承载随机IO600/s,但是这个参数设置为300,那就是白白浪费了一些ssd的性能.所以应先将ssd的最大随机速率做一个测试,可以使用fio工具,测试出值以后再把innodb_io_capacity这个参数设置为这个值,这样就可以让数据库以最大速率flush缓存页到磁盘了.还有一个参数是innodb_flush_neighbors,作用是在flush缓存页到磁盘的时候可能会控制把缓存页临近的其他缓存页也刷到磁盘,这样有时候就会导致需要flush的缓存页太多了.如果使用的事ssd的话,没有必要让它同时刷邻近的缓存页,直接把innodb_flush_neighbors设置为0,这样把每次flush的缓存页数量降到最低,性能抖动就可以降到最小





**MySQL索引**

Mysql会通过主键建一颗B+树,树的叶子节点是数据页,这种情况也成为聚簇索引

当建非主键索引时,会新建一棵B+树,但此时叶子节点的数据页只会放索引字段的值和主键的值,比如字段age,那此时的数据页则只包含age和主键的值

联合索引:  比如name+age,也是一棵独立的B+树,默认按照name排序,name一样就按照age排序

比如现在select * from xxx where age=1,先从age索引的树中查找到主键的值,再进行"回表",即再到聚簇索引里从根节点开始找到主键对应的叶子节点的数据页,定位到主键对应的完整数据行,此时才能拿到完整的行数据

在非主键索引的B+树中,比如name的,name的B+树的索引页中,除了存放页号和最小name字段值意外,每个索引页还会存放那个最小name字段值对应的主键值,这是因为有时候会出现多个索引页指向的下层页号的最小name字段值是一样的,此时就必须根据主键判断一下

![image-20210512154507659](C:\Users\EDZ\Desktop\note'\rocket\image-20210512154507659.png)

联合索引的规则

1.等值匹配规则

2.最左侧列匹配   

比如现在联合索引是(name,class,subject),那sql语句where条件只用name和class是可以的,不一定要全用,只用name也可以,但是不能只用class,subject或任意一项,需要先匹配了最左边的列才能继续后面的

3.最左前缀匹配原则

like模糊查询,比如name like '张%',查找张开头的分数,也是可以基于索引查找的,但是"%张"就不能走索引了,因为并不知道最左前缀是什么

4.范围查找规则

where语句里如果有范围查询,只有对联合索引里最左侧的列进行范围查询才能用到索引

5.等值匹配+范围匹配规则

可以先用最左字段定位一批数据,再在这批数据里通过索引查找,如select * from student where name="zhang" and class <10 ,但是如果最后再加一个and subject < "math",那subject是不能用索引的.



排序时使用索引,在sql语句排序时尽量按照联合索引的字段顺序去进行order by排序,这样可以直接联系联合索引树里的数据有序性,到索引树里直接按照字段值的顺序去获取需要的数据.如索引(xx1,xx2,xx3) order by xx1,xx2,xx3,desc或asc都可以,但是不能有点字段desc有的asc,这样是走不了索引的

group by也是可以走索引的,与排序用的同理

查找数据时,尽量只查联合索引覆盖的字段,避免回表操作!



**设计索引**

1.保证order,where,group by后面跟的字段都是联合索引的最左侧开始的部分字段,这样全部能走索引

2.基数: 选用基数比较大的字段建立索引,不要选择如status这种只有0或1两种值的,这种基数太小,根本没法进行快速二分查找,建索引也没什么意义了

3.前缀索引: 尽量对长度较小的字段建立索引,当然,有些字段即使很长varchar(255),但使用的频率特别高,也还是需要建索引的,这种情况,如果觉得数据量特别大,建这样的索引树特别占空间的话,可以换一种策略,比如说只对这个varchar(255)字段的前20个字符建立索引,类似于KEY my_index(name(20),age,course),这样的形式,根据name字段搜索的时候,就会先到索引树里根据name字段的前20个字符去搜索,定位到之后前20个字符的前缀匹配的部分数据之后,再回到聚簇索引提取出来完整的name字段值进行比对就可以了.
但是这种只取一部分长度建立索引的情况,如果碰上order by name或者group by就不起作用了,这时候就不走索引了,这是前缀索引失效的地方

4.联合索引尽量不超过3个,尽量做到3个覆盖所有查询,主键一定要是自增的,这一点最起码保证聚簇索引不会频繁分裂



**索引设计实战**

1.类似于select * form table where age=18 and order by score这样的sql,where和order是没法都用的索引的,如果是联合索引,age在最左侧,那where是可以走索引,但是order是走不了了.如果针对age和score分别设计两个索引的话,但是因为先基于age做了筛选,那么是没法利用score索引进行排序的

那么在有where和order by的情况下给谁用索引呢?一般都是where走索引的,因为where可以最大程度上快速筛选数据,筛选后的数据量不是太大的话,后续排序和分页的成本不会太大

2.在联合索引的sql中,一旦一个字段做范围查询用到了索引,那么这个字段接下来的条件都不能用索引了!所以实际设计索引的时候,必须把经常用做范围查询的字段放在联合索引的最后一个,才能保证sql里的每个字段都能基于索引去查询

3.对于一些使用频繁但基础不大的值也可以加入索引,比如爱好只有10种,省份只有三十几个,将这些字段放在最前面,用到的时候就直接等值就可以了,用不到这些字段筛选的时候也可以直接通过hobby in (xx,xx) and province in (xx,xx)这种in条件的方式来使联合索引后面的字段能用到索引,不然联合索引没先查前面(左侧的字段的话,不能直接对面后面的字段走索引

要把索引设计成**（province, city, sex, hobby, character, age**）这样的一个形式。这么做其实关键是要让最频繁查询的一些条件都放到索引里去，然后在查询的时候如果有些字段是不使用的，可以用in (所有枚举值)的方式去写，这样可以让所有查询条件都用上你的索引，同时对范围查询的age字段必须放在最后一个，这样保证范围查询也能用上索引。

4.基于陌生人社交app的前提,比如说查询匹配的用户时还需要一个条件,用户是否7天内登陆过,有个字段last_login_time,,如果要加一个last_login_time<=7天内的类似语句,那这个肯定没法用索引了,因为这里肯定需要用一些计算或者是函数,才能进行时间的对比.或者把last_login_time加到联合索引里去,做一个范围查询,7天内就可以改成time>xxx and time<xxx,但是在联合索引里,这一定是和age共用的,两个范围查询同时使用必定会导致另一个走不了索引.此时可以换一个思路,设计一个7天内是否登陆过的字段,值为0或1,早先在业务层更改这个字段,后面直接等值查询这个字段就可以了,

5.基于基数很小的字段来筛选,比如就基于性别来筛选，比如一下子筛选出所有的女性，可能有上百万用户数据，接着还要磁盘文件进行排序再分页？那这个性能可能就会极为的差劲了！所以针对上述问题，可以针对那种基数很低的字段再加上排序字段单独额外设计一个辅助索引，专门用于解决where条件里都是基数低的字段，然后还要排序后分页的问题，比如说就可以设计一个联合索引为：（sex, score）,sql: select xx from user where sex=female and order by score limit xx ,xx,此时因为where是等值匹配,所以order by后面跟的字段是(sex,score)索引里的第二个字段,order by没有从索引最左侧字段开始排列,但是他也可以使用到索引来排序.

**核心重点就是，尽量利用一两个复杂的多字段联合索引，抗下你80%以上的 查询，然后用一两个辅助索引抗下剩余20%的非典型查询，保证你99%以上的查询都能充分利用索引，就能保证你的查询速度和性能！**





**执行计划**

const 直接走聚簇索引

ref      普通索引等值匹配

ref_or_null  普通索引等值匹配加上is null的情况

range  普通索引范围查询

index   查的字段正好是联合索引的字段,但是条件不符合最左原则,比如可能是(age,name,sex) select age,name,sex from user where name ="",走不了索引,但字段正好在对应的树上,就会去这个联合索引的树上去遍历,找到之后直接取出叶子节点,index就是这种只要遍历二级索引就可以拿到你想要的数据,而不需要回表的情况

all    全表扫描



**force index优化**

有时候观察执行计划,发现sql没有走预期的索引,它自动选择了不合适的索引,这时候通过强制指定索引可以进行优化

比如 select * from products where category='xx' and sub_category='xx' order by id desc limit xx,xx

执行计划里possible keys里有index_category,但是实际的key不是这个索引,而是primary,Extra写的是using where,也就是说本质是在聚簇索引上进行扫描.一边扫描一遍用where的条件去进行筛选,

通过force index语法强制指定索引,可以优化成正常情况,亿级数据从几十s优化到一两百ms

select * from products force index(index_category) where category='xx' and sub_category='xx'  order by id desc limit xx,xx

那为什么最初上面的sql会自动帮你走聚簇索引呢?在亿级数据的情况下,因为是select *,所以最终查到id是要回表的,担心说比如查出来了几万条数据,最后还得order by id desc排序,对这几万条数据的临时磁盘文件进行file sort磁盘排序,排序之后再limit取出指定位置的数据,再回聚簇索引回表.

所以mysql就是担心二级索引查出来的数据太多,还得在临时磁盘里排序,可能性能会很差,mysql就把它判断为了一种不太好的方式.就选择了换成直接扫描聚簇索引,因为聚簇索引的id都是有序的,直接按order by的顺序扫描过去,匹配出limit的数据就行了.

其实在一般情况下,mysql的这种优化也是不慢的,通常where条件是有返回值的,通常很快能找到符合条件的数据并返回.但是有可能某天新增了一些品类,然后用户对这些品类以及子类进行筛选,但是并没有对应的数据,底层在扫描聚簇索引的时候就发现扫来扫去都扫不到符合where条件的结果,一下就把聚簇索引全部扫了一遍,等于上亿数据全表扫描了,这种情况就会导致sql特别的慢

这种sql的优化一定要结合执行计划以及实际业务场景来考量



**Mysql主从架构数据传输**





![image-20210521140828875](C:\Users\EDZ\Desktop\note'\mysql\pic\image-20210521140828875.png)





分库分表的思路

用户表:  对userId进行hash取模,比如分100个表,登录时用的是username,再建立一个username-->userId的映射表,再对username进行hash取模分表,先通过username查userId,再查user完整数据

订单表:用户端也可以同理于用户表,通过对orderid取模,再建立userid-->orderid的映射表,但是商户端就没法通过这样查表了,此时就再建立商户的映射.如果是平台要通过很多复杂条件来查订单,此时就不适应mysql了,这种复杂查询最好通过es来处理

用户查订单有时除了分页可能还有一些订单状态,商品名之类的查询条件,最简单的方法直接从原来的映射表中加上这些字段即可