synchronized 通过monitor控制锁,加锁时是monitor enter,释放锁时是monitor exit,加锁时先判断对象的monitor的计数器的值,如果其中不为0,那么说明已经被加锁了,再看加锁对象是不是自己,是自己则可以重复加锁,否则阻塞等待,可保证有序性,原子性,可见性

java对象都是分为对象头和实例变量两块的，其中实例变量就是大家平时看到的对象里的那些变量数据。然后对象头包含了两块东西，一个是Mark Word（包含hashCode、锁数据、GC数据，等等），另一个是Class Metadata Address（包含了指向类的元数据的指针）
在Mark Word里就有一个指针，是指向了这个对象实例关联的monitor的地址，这个monitor是c++实现的，不是java实现的。这个monitor实际上是c++实现的一个ObjectMonitor对象，里面包含了一个_owner指针，指向了持有锁的线程。_
ObjectMonitor里还有一个entrylist，想要加锁的线程全部先进入这个entrylist等待获取机会尝试加锁，实际有机会加锁的线程，就会设置owner指针指向自己，然后对count计数器累加1次
各个线程尝试竞争进行加锁，此时竞争加锁是在JDK 1.6以后优化成了基于CAS来进行加锁，理解为跟之前的Lock API的加锁机制是类似的，CAS操作，操作count计数器，比如说将_count值尝试从0变为1



synchronized的执行过程： 
\1. 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁 
\2. 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位 
\3. 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。 
\4. 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁 
\5. 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 
\6. 如果自旋成功则依然处于轻量级状态。 
\7. 如果自旋失败，则升级为重量级锁。



volatile  保证有序性和可见性,无法完全保证原子性

通过内存屏障,在使用volatile修饰的变量时,会发送一条lock指令到cpu,它的作用是当本次操作完成以后,会强制使其他线程的工作内存里的该变量失效,必须重新从主存中获取值.并且被修饰的变量,在他的读写期间,代码是无法被重新排序的.

在volatile变量写操作的前面会加入一个Release屏障，然后在之后会加入一个Store屏障，这样就可以保证volatile写跟Release屏障之前的任何读写操作都不会指令重排，然后Store屏障保证了，写完数据之后，立马会执行flush处理器缓存的操作

Java内存模型,用来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果，增强了Java程序的可移植性。主内存-->工作内存-->执行引擎,取值时是Read-->Load-->Use,存回去时是Assign-->Store-->Write



ConcurrentHashMap   1.7之前是对底层数组分段加锁,1.8的是采用cas对数组的空节点赋值,如果节点已经有值,就对节点(链表/红黑树)用synchronized加锁,完成操作.如果节点是转移节点的话,说明数组正在扩容,则一直自旋等到扩容完成.

扩容时,会锁住所有的节点,扩容后,拷贝旧数组到新数组时,正在拷贝的节点会变成转移节点transfer,这样有put操作进来时,发现这个节点是转移节点就会一直等待,直到扩容拷贝都完成后,把新数组的值赋值给数组容器,之前等待得put操作才能继续put



HashTable是线程安全的,是直接synchronized全局加锁,但可能会死循环,互相应用



JIT指令重排,单例模式的double check就是防止这个

1.分配地址 2.初始化对象 3.将对象指向分配的地址  重排地址可能导致1,3,2, 有可能对象还没初始化完,但已经有了引用,这时候去调用就会引发NPE异常





JVM对锁的优化

1.锁消除,不使用monitor加锁

2.锁粗化,避免多次重复加锁释放锁 ,如果有段代码连续加锁释放锁多次,会结合为一个锁

3.偏向锁,如果发现大概率只会有一个线程来竞争锁,那么就维护一个偏好Bias,后面他加锁释放锁都基于Bias来做,不基于CAS  (它通过消除资源无竞争情况下的同步原语,进一步提高了程序的运行性能)

4.轻量级锁, 如果偏向锁没能成功实现，就是因为不同线程竞争锁太频繁了，此时就会尝试采用轻量级锁的方式来加锁，就是将对象头的Mark Word里有一个轻量级锁指针，尝试指向持有锁的线程，然后判断一下是不是自己加的锁,如果是自己加的锁，那就执行代码就好了,如果不是自己加的锁，那就是加锁失败，说明有其他人加了锁，这个时候就是升级为重量级锁

5.适应性锁,这是JIT编译器对锁做的另外一个优化，如果各个线程持有锁的时间很短，那么一个线程竞争锁不到，就会暂停，发生上下文切换，让其他线程来执行。但是其他线程很快释放锁了，然后暂停的线程再次被唤醒.也就是说在这种情况下，线程会频繁的上下文切换，导致开销过大,所以对这种线程持有锁时间很短的情况，是可以采取忙等策略的，也就是一个线程没竞争到锁，进入一个while循环不停等待，不会暂停不会发生线程上下文切换，等到机会获取锁就继续执行好了



JMAP获取jvm快照,用JProfiler分析内存占用情况,还可以动态链接线上机器,动态看内存变化





双亲委派加载机制可以防止类的重复加载,避免核心类错误加载,api被篡改



tomcat破坏了java的双亲委派模型

1.同一个web容器中,同一个库的不同版本需要互相隔离(默认加载器时不管类库的版本的,只看类的全限定名),保证每个应用的程序的类库都是独立的

2.同一个web容器中,同一个库的相同版本,可以共同引用,不用给每个应用加载一份类库到jvm中

3.在java中,jsp是会被编译成class加载到jvm中的,而tomcat可以让修改jsp后不重启应用就生效,原理就是当jsp文件改动后,卸载掉原来的那个class的加载器,重新创建新的类加载器(每个jsp文件对应一个类加载器)

4.web容器自己也有依赖的类库,不能与应用程序的类库混淆,基于安全考虑,需要让容器与应用程序的类库隔离开来



tomcat的每个WebAppClassLoader加载自己目录下的class文件,不会传递给父类加载器.





线程池

四大拒绝策略

1直接丢弃 2.丢弃并抛出异常  3.callerRuns 4.abort oldest

如果是定时线程池,则直接用delayQueue作为队列即可



Arthas排查响应时间长的服务

启动arthas后,选择java进程,trace  类全限定名 方法,追踪方法的整个执行过程以及具体执行时间



排查占用cpu高的代码问题

jps找到java进程,然后top -Hp pid看占用cpu最高的线程,再打印tid的16进制,再jstack tid查看具体消耗在哪